{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-28T23:35:35.792843Z 2017-05-27T23:35:35.792843Z\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import geomagio\n",
    "from obspy.core import UTCDateTime\n",
    "import urllib.request, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geomagio\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "endtime =  UTCDateTime(datetime.datetime.utcnow())-60*86400.\n",
    "starttime =  endtime-60*86400.\n",
    "print(starttime, endtime)\n",
    "\n",
    "#url = \"https://geomag.usgs.gov/ws/edge/?id=BOU&format=json\"\n",
    "#url = url + \"&starttime=2017-07-10T00:00:00Z\"\n",
    "#url = url + \"&endtime=2017-07-18T00:00:00Z\"\n",
    "#url = url + \"&type=adjusted\"\n",
    "#response = urllib.request.urlopen(url)\n",
    "#data = json.loads(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BOU (86401,) 20565.2621764 3340.49741308 47192.7953605\n",
      "1 BRW (86401,) 8495.92124494 3350.41406633 56827.0508671\n",
      "2 BSL (86401,) 23265.8480219 316.42638562 40910.4215459\n",
      "3 CMO (86401,) 11340.6979819 4885.04679147 55328.9556046\n",
      "4 DED (86401,) 8626.45338325 2875.22884565 56734.225341\n",
      "5 FRD (86401,) 21243.8039132 -3523.9905709 45668.8194582\n",
      "6 FRN (86401,) 22692.6491737 5804.62253477 42120.4937506\n",
      "7 GUA (86401,) 35236.10182 862.302829643 7668.00561145\n",
      "8 HON (86401,) 26889.4595616 5046.48601805 21072.6571014\n",
      "9 NEW (86401,) 17079.049608 5504.79625427 50727.9198405\n",
      "10 SHU (86401,) 18903.3529718 6016.27063723 48634.1288748\n",
      "11 SIT (86401,) 14467.869073 6308.67291106 52451.4425862\n",
      "12 SJG (86401,) 26354.815969 -5411.51430346 24982.9363562\n",
      "13 TUC (86401,) 24082.730606 4582.42401287 40219.9390275\n"
     ]
    }
   ],
   "source": [
    "OBSERVATORIES = ('BOU', 'BRW', 'BSL', 'CMO', 'DED', 'FRD',\n",
    "                 'FRN', 'GUA', 'HON', 'NEW', 'SHU', 'SIT', \n",
    "                 'SJG', 'TUC')\n",
    "\n",
    "CHANNELS = ('X', 'Y', 'Z')\n",
    "\n",
    "nchannels = len(CHANNELS)*len(OBSERVATORIES)\n",
    "\n",
    "input_factory = geomagio.edge.EdgeFactory()\n",
    "#starttime = datetime.datetime.utcnow()\n",
    "#endtime = starttime\n",
    "\n",
    "for i, obs in enumerate(OBSERVATORIES):\n",
    "    timeseries = input_factory.get_timeseries(\n",
    "        observatory = obs,\n",
    "        channels = CHANNELS,\n",
    "        type = 'variation',\n",
    "        interval = 'minute',\n",
    "        starttime = starttime,\n",
    "        endtime = endtime)\n",
    "    if i == 0:\n",
    "        data = np.zeros([len(CHANNELS)*len(OBSERVATORIES),timeseries[0].data.shape[0]],dtype='float')\n",
    "    print(i,obs,timeseries[0].data.shape, np.nanmean(timeseries[0].data),\n",
    "          np.nanmean(timeseries[1].data),np.nanmean(timeseries[2].data))\n",
    "    \n",
    "    for j in range(len(CHANNELS)):\n",
    "        length = timeseries[j].data.shape[0]\n",
    "        data[i*len(CHANNELS)+j,0:length] = (timeseries[j].data[0:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeseries.shape= (42, 525600)\n",
      "nchannels= 42\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "DIR = \"/data/st/geomag_2010_2016_xyzf/\"\n",
    "#FILENAME = 'F_2015_minutes.pkl'\n",
    "#timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "#for o in range(timeseries.shape[0]):\n",
    "#    timeseries2[o*4+0,:] = timeseries[o,:]\n",
    "FILENAME = 'X_2015_minutes.pkl'\n",
    "timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "timeseries2=np.zeros([len(OBSERVATORIES)*len(CHANNELS),timeseries.shape[1]],dtype='float')\n",
    "for o in range(timeseries.shape[0]):\n",
    "    timeseries2[o*3+0,:] = timeseries[o,:]\n",
    "FILENAME = 'Y_2015_minutes.pkl'\n",
    "timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "for o in range(timeseries.shape[0]):\n",
    "    timeseries2[o*3+1,:] = timeseries[o,:]\n",
    "FILENAME = 'Z_2015_minutes.pkl'\n",
    "timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "for o in range(timeseries.shape[0]):\n",
    "    timeseries2[o*3+2,:] = timeseries[o,:]\n",
    "timeseries = timeseries2\n",
    "    \n",
    "print(\"timeseries.shape=\",timeseries.shape)\n",
    "\n",
    "data = timeseries[:,:]\n",
    "nchannels = data.shape[0]\n",
    "print(\"nchannels=\",nchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.shape (8760,)\n",
      "nchannels= 42\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ef7a79f6fa45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msampled_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_to_sampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done raw_to_sampled, sampled_values.shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mcheung/FDL/solar-terrestrial/sting.py\u001b[0m in \u001b[0;36mraw_to_sampled\u001b[0;34m(raw_values, window)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m#Interpolate over nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0msampled_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import sting\n",
    "\n",
    "lags = np.array(range(1))\n",
    "batch_size=1\n",
    "\n",
    "# Average\n",
    "window = 60\n",
    "sampled_values, time = sting.raw_to_sampled(data, window)\n",
    "print(\"Done raw_to_sampled, sampled_values.shape\", sampled_values.shape)\n",
    "\n",
    "scalers_file = 'scalers_window{0:03d}_lags{1:03d}.pkl'.format(window, np.max(lags))\n",
    "scalers = pickle.load(open(scalers_file,'rb'),  encoding=\"latin1\")\n",
    "\n",
    "train_scaled, test_scaled, scalers2 = sting.sampled_to_scaled(sampled_values, \n",
    "                                                              time, nchannels, \n",
    "                                                              lags, batch_size, \n",
    "                                                              scalers=scalers)\n",
    "print(train_scaled.shape,test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = \"model_window{0:03d}_lags{1:03d}.json\".format(window, np.max(lags))\n",
    "model_file= \"lstm_model_window{0:03d}_lags{1:03d}.h5\".format(window, np.max(lags))\n",
    "\n",
    "json_file = open(json_file, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_file)\n",
    "loaded_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeats = 1\n",
    "predictions = np.zeros([test_scaled.shape[0],test_scaled.shape[1]])\n",
    "predictions[0,:] = test_scaled[0,:]\n",
    "\n",
    "for r in range(repeats):    \n",
    "    for i in (range(test_scaled.shape[0]-2)):\n",
    "        # make one-step forecast\n",
    "        if i > int(0.7*test_scaled.shape[0]):\n",
    "            X = yhat\n",
    "            yhat = sting.forecast_lstm(loaded_model, 1, X)\n",
    "            yhat = yhat[0,:]\n",
    "            predictions[i+1,:] = yhat\n",
    "        else:\n",
    "            X = test_scaled[i, :]\n",
    "            yhat = sting.forecast_lstm(loaded_model, 1, X)\n",
    "            yhat = yhat[0,:]\n",
    "            predictions[i+1,:] = test_scaled[i+1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "print(predictions.shape)\n",
    "print(test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_predictions = predictions.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "inverted_test = test_scaled.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "\n",
    "for c in range(len(scalers2)):\n",
    "    sc = scalers2[c]\n",
    "    #inverted_predictions[:,:,c] = \n",
    "    #inverted_predictions[:,:,c] = sc.inverse_transform(inverted_predictions[:,:,c])\n",
    "    #inverted_test[:,:,c] = \n",
    "    #inverted_test[:,:,c] = sc.inverse_transform(inverted_test[:,:,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(inverted_predictions[:,len(lags)-1,12])\n",
    "#plt.plot(inverted_test[:,len(lags)-1,12],'--')\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for c in range(nchannels):\n",
    "    plt.figure(c)\n",
    "    obs = int(np.floor(c/len(CHANNELS)))\n",
    "    comp = c % len(CHANNELS)\n",
    "    x = inverted_test[:,len(lags)-1,c]\n",
    "    y = inverted_predictions[:,len(lags)-1,c]\n",
    "    plt.plot(x)\n",
    "    plt.plot(y,'--')\n",
    "    #pyplot.ylim(predictions[:,len(lags)-1,c].min(),predictions[:,len(lags)-1,c].max())\n",
    "    plt.xlim(int(0.68*test_scaled.shape[0]),int(0.75*test_scaled.shape[0]))\n",
    "    plt.ylim(np.array([x,y]).min(),np.array([x,y]).max())\n",
    "    corr = pearsonr(x,y)\n",
    "    plt.title(\"{0} ({1}), pearson r={2:.2f}, p={3:.3f}\".format(OBSERVATORIES[obs],CHANNELS[comp],corr[0],corr[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeseries = input_factory.get_timeseries(\n",
    "#        observatory = obs,\n",
    "#        channels = CHANNELS,\n",
    "#        type = 'variation',\n",
    "#        interval = 'minute',\n",
    "#        starttime = UTCDateTime('2013-03-28T20:41:16.951677Z'),\n",
    "#        endtime = UTCDateTime('2014-03-28T20:41:16.951677Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
