{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sting'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a3c7002565d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mconfigparser\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sting'"
     ]
    }
   ],
   "source": [
    "#Heavily modified from \n",
    "#http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "#contact: Mark Cheung, cheung@lmsal.com\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "if sys.version_info <= (3,5):\n",
    "    import ConfigParser\n",
    "else:\n",
    "    import configparser as ConfigParser\n",
    "import sting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read local config file\n",
    "config = ConfigParser.RawConfigParser()\n",
    "config.read('myconfig.cfg')\n",
    "DIR = config.get('LSTMCFG','DIR')\n",
    "FILENAME = config.get('LSTMCFG','FILENAME')\n",
    "batch_size = int(config.get('LSTMCFG', 'BATCH_SIZE'))\n",
    "#OUTPUT = config.get('LSTMCFG','OUTPUT')\n",
    "#TIMES = map(int, config.get('LSTMCFG','TIMES').split(','))\n",
    "#nb_epoch = int(config.get('LSTMCFG', 'NB_EPOCH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load USGS data\n",
    "OBSERVATORIES = ('BOU', 'BRW', 'BSL', 'CMO', 'DED', 'FRD',\n",
    "    'FRN', 'GUA', 'HON', 'NEW', 'SHU', 'SIT', 'SJG', 'TUC')\n",
    "CHANNELS = ('X', 'Y', 'Z') \n",
    "\n",
    "# Number of magnetic channels/components per observatory\n",
    "nchannels = len(CHANNELS)\n",
    "\n",
    "DIR = \"/data/st/geomag_2015_2016_xyzf/\"\n",
    "FILENAME = 'X_2015_minutes.pkl'\n",
    "timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "timeseries2=np.zeros([len(OBSERVATORIES)*nchannels,timeseries.shape[1]],dtype='float')\n",
    "for o in range(timeseries.shape[0]):\n",
    "    timeseries2[o*3+0,:] = timeseries[o,:]\n",
    "FILENAME = 'Y_2015_minutes.pkl'\n",
    "timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "for o in range(timeseries.shape[0]):\n",
    "    timeseries2[o*3+1,:] = timeseries[o,:]\n",
    "FILENAME = 'Z_2015_minutes.pkl'\n",
    "timeseries=np.array(pickle.load(open(DIR + FILENAME,'rb'),  encoding=\"latin1\"))\n",
    "for o in range(timeseries.shape[0]):\n",
    "    timeseries2[o*3+2,:] = timeseries[o,:]\n",
    "timeseries = timeseries2\n",
    "    \n",
    "print(\"timeseries.shape=\",timeseries.shape)\n",
    "\n",
    "raw_values = timeseries[:,:]\n",
    "nchannels = raw_values.shape[0]\n",
    "\n",
    "# Subsample / average in time\n",
    "# Averaging window for subsampling in time\n",
    "window = 60 \n",
    "sampled_values, time = sting.raw_to_sampled(raw_values,window)\n",
    "\n",
    "# Now we create rows that comprise of timeseries data with different lags, all concatenated together.\n",
    "lags = np.array([0],dtype='int')\n",
    "\n",
    "#print(\"sampled_values.shape\",sampled_values.shape)\n",
    "#print(sampled_values[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in range(nchannels):\n",
    "    if np.isnan(np.nanmean(timeseries[i,:])):\n",
    "        print(i,np.nanmean(timeseries[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "train_scaled, test_scaled, scalers = sting.sampled_to_scaled(sampled_values, time, nchannels, lags, batch_size)\n",
    "print(train_scaled.shape, test_scaled.shape)\n",
    "print('len(scalers)',len(scalers))\n",
    "#Save scaling functions\n",
    "pickle.dump(scalers, open(\"scalers_window{0:03d}_lags{1:03d}.pkl\".format(window,np.max(lags)),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#from scipy import interpolate\n",
    "#time = np.arange(np.floor(raw_values.shape[1]/window),dtype='int')*window\n",
    "#print(time)\n",
    "#print(raw_values.shape)\n",
    "#i= 0\n",
    "#y = raw_values[i,time].ravel()\n",
    "#good = np.isfinite(y)\n",
    "#f = interpolate.interp1d(time[good].astype(float), y[good],fill_value='extrapolate')\n",
    "#sampled_values[i,:] = f(time.astype(float))\n",
    "#sampled_values, time = sting.raw_to_sampled(raw_values,window)\n",
    "#plt.plot(raw_values[i,:])\n",
    "\n",
    "def rebin(a, *args):\n",
    "    import numpy as np\n",
    "    '''rebin ndarray data into a smaller ndarray of the same rank whose dimensions\n",
    "    are factors of the original dimensions. eg. An array with 6 columns and 4 rows\n",
    "    can be reduced to have 6,3,2 or 1 columns and 4,2 or 1 rows.\n",
    "    example usages:\n",
    "    >>> a=rand(6,4); b=rebin(a,3,2)\n",
    "    >>> a=rand(6); b=rebin(a,2)\n",
    "    '''\n",
    "    shape = a.shape\n",
    "    lenShape = len(shape)\n",
    "    factor = np.asarray(shape)/np.asarray(args)\n",
    "    evList = ['a.reshape('] + \\\n",
    "             ['args[%d],factor[%d],'%(i,i) for i in range(lenShape)] + \\\n",
    "             [')'] + ['.sum(%d)'%(i+1) for i in range(lenShape)] + \\\n",
    "             ['/factor[%d]'%i for i in range(lenShape)]\n",
    "    print(''.join(evList))\n",
    "    return eval(''.join(evList))\n",
    "\n",
    "img = imresize(np.isfinite(raw_values).astype(int),(timeseries.shape[0], timeseries.shape[0]),interp='nearest')\n",
    "print(img.max(),img.min())\n",
    "pyplot.imshow(img)\n",
    "\n",
    "print(raw_values.min(),raw_values.max())\n",
    "#test = rebin(np.isfinite(timeseries),timeseries.shape[0],timeseries.shape[0])#)\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat experiment\n",
    "repeats = 1\n",
    "error_scores = list()\n",
    "# for r in range(repeats):\n",
    "# fit the model\n",
    "lstm_model, lstm_model_pred = sting.fit_lstm_deep(train_scaled, batch_size, 201, nchannels*2)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "# walk-forward validation on the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save trained model. The difference between lstm_model and lstm_model_pred is that the latter has batch_size=1\n",
    "lstm_model.save_weights('lstm_model_window{0:03d}_lags{1:03d}.h5'.format(window,np.max(lags)))\n",
    "lstm_model_pred.load_weights('lstm_model_window{0:03d}_lags{1:03d}.h5'.format(window,np.max(lags)))\n",
    "model_json = lstm_model_pred.to_json()\n",
    "with open(\"model_window{0:03d}_lags{1:03d}.json\".format(window,np.max(lags)), \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.zeros([test_scaled.shape[0],test_scaled.shape[1]])\n",
    "for r in range(repeats):    \n",
    "    for i in range(len(test_scaled)-1):\n",
    "        # make one-step forecast\n",
    "        X, y = test_scaled[i, :], test_scaled[i+1,:]\n",
    "        #X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "        yhat = sting.forecast_lstm(lstm_model_pred, 1, X)\n",
    "        yhat = yhat[0,:]\n",
    "        # store forecast\n",
    "        predictions[i,:] = yhat\n",
    "        # report performance\n",
    "        #rmse = sqrt(mean_squared_error(raw_values[len(time)-wall:], predictions))\n",
    "        #rmse_baseine = sqrt(mean_squared_error(raw_values[len(time)-wall:], shift(predictions,-1)))    \n",
    "        #print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        #print('%d) Test RMSE: %.3f' % (r+1, rmse_baseline))\n",
    "        #error_scores.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_scaled.shape,predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_predictions = predictions.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "inverted_test = test_scaled.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "#for c in range(len(scalers)):\n",
    "#    sc = scalers[c]\n",
    "#    inverted_predictions[:,c] = sc.inverse_transform(predictions[:,c].ravel())\n",
    "#    inverted_test[:,c] = sc.inverse_transform(test_scaled[:,c].ravel())\n",
    "\n",
    "#inverted_predictions = inverted_predictions.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "print(\"predictions.shape\",inverted_predictions.shape)\n",
    "#inverted_test = inverted_test.reshape([predictions.shape[0],lags.shape[0],nchannels])\n",
    "print(\"inverted_test.shape\",inverted_test.shape)\n",
    "\n",
    "for c in range(len(scalers)):\n",
    "    sc = scalers[c]\n",
    "    #inverted_predictions[:,:,c] = \n",
    "    sc.inverse_transform(inverted_predictions[:,:,c])\n",
    "    #inverted_test[:,:,c] = \n",
    "    sc.inverse_transform(inverted_test[:,:,c])\n",
    "\n",
    "#print(inverted_predictions[:,3,0])\n",
    "#print(inverted_test[:,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for c in range(nchannels):\n",
    "    pyplot.figure(c)\n",
    "    obs = int(np.floor(c/len(CHANNELS)))\n",
    "    comp = c % len(CHANNELS)\n",
    "    x = inverted_test[:,len(lags)-1,c]\n",
    "    y = inverted_predictions[:,len(lags)-1,c]\n",
    "    pyplot.fill(x)\n",
    "    pyplot.plot(y,color='orange')\n",
    "    #pyplot.ylim(predictions[:,len(lags)-1,c].min(),predictions[:,len(lags)-1,c].max())\n",
    "    pyplot.xlim(0,100)\n",
    "    pyplot.ylim(x.min(),x.max())\n",
    "    corr = pearsonr(x,y)\n",
    "    pyplot.title(\"{0} ({1}), pearson r={2:.2f}, p={3:.3f}\".format(OBSERVATORIES[obs],CHANNELS[comp],corr[0],corr[1]))\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "#metric = np.array([2,inverted_test.shape[2]])\n",
    "f = open(\"model_window{0:03d}_lags{1:03d}.metrics\".format(window,np.max(lags)), \"w\")\n",
    "\n",
    "for c in range(inverted_test.shape[2]):\n",
    "    pyplot.figure(c)\n",
    "    obs = int(np.floor(c/len(CHANNELS)))\n",
    "    comp = c % len(CHANNELS)\n",
    "\n",
    "    x = inverted_test[:,len(lags)-1,c]\n",
    "    y = inverted_predictions[:,len(lags)-1,c]\n",
    "    pyplot.hist2d(x, y, bins=40, norm=LogNorm())\n",
    "    pyplot.colorbar()\n",
    "    corr = pearsonr(x,y)\n",
    "    pyplot.title(\"{0} ({1}), pearson r={2:.2f}, p={3:.3f}\".format(OBSERVATORIES[obs],CHANNELS[comp],corr[0],corr[1]))\n",
    "    pyplot.show()\n",
    "    f.write('{0} ({1}), pearson r={2:.2f}, p={3:.3f}\\n'.format(OBSERVATORIES[obs],CHANNELS[comp],corr[0],corr[1]))\n",
    "    \n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(inverted_test.shape[2]):\n",
    "    pyplot.figure(c)\n",
    "    obs = int(np.floor(c/len(CHANNELS)))\n",
    "    comp = c % len(CHANNELS)\n",
    "\n",
    "    x = inverted_test[0:-2,len(lags)-1,c]\n",
    "    y = inverted_test[1:-1,len(lags)-1,c]\n",
    "    pyplot.hist2d(x, y, bins=40, norm=LogNorm())\n",
    "    #pyplot.axis('equal')\n",
    "    #pyplot.axis([-5,5,-5,5])\n",
    "    pyplot.colorbar()\n",
    "    corr = pearsonr(x,y)\n",
    "    pyplot.title(\"{0} ({1}), pearson r={2:.2f}, p={3:.3f}\".format(OBSERVATORIES[obs],CHANNELS[comp],corr[0],corr[1]))\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
